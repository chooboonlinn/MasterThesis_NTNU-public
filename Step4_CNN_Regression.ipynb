{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import time\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run ./CommonFunctions_OthersGeneral.ipynb  ## This is important for library import, getting the path and runlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Markus's codes:\n",
    "# For Angles\n",
    "\n",
    "def cyclic_mean_abs_error(y_true, y_pred):\n",
    "    return K.mean(K.minimum(K.abs(y_pred - y_true),K.minimum(K.abs(y_pred - y_true + 2*np.pi),\n",
    "                                                             K.abs(y_pred - y_true - 2*np.pi))), axis=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourth # Improved\n",
    "# Combined opions\n",
    "# Original\n",
    "\n",
    "def create_cnn_functional_model(angles,num_layers):\n",
    "    if angles == 'yes':\n",
    "        input_layer = Input(shape=(108,192,3))\n",
    "\n",
    "        ## Downsampling here (Flexible to alter)\n",
    "        X = Conv2D(64, kernel_size=(7,7), activation='relu', strides = (1,1), padding='same')(input_layer)\n",
    "        for l in range(0, num_layers):\n",
    "            X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,1), padding='same')(X)\n",
    "            X = Dropout(0.25)(X)\n",
    "            X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (1,2), padding='same')(X)\n",
    "            X = Dropout(0.25)(X)\n",
    "            X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,2), padding='same')(X)\n",
    "            X = Dropout(0.25)(X) \n",
    "\n",
    "        X = Flatten()(X)\n",
    "        X = Dense(128, activation=\"linear\", kernel_regularizer=regularizers.l2(0.01), \n",
    "                  activity_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(X)\n",
    "        #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), \n",
    "        #          activity_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005)\n",
    "        #          ,bias_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005))(X)\n",
    "        X = Dropout(0.50)(X)\n",
    "\n",
    "        #output = Dense(3, activation=\"linear\")(X) # linear is default\n",
    "        #model = Model(inputs=input_layer, outputs=output)\n",
    "        output1_xy = Dense(units=2, activation=\"linear\",name='output1_xy')(X) # linear is default\n",
    "        output2_angles = Dense(units=1, activation=\"linear\",name='output2_angles')(X) # linear is default\n",
    "        model = Model(inputs=input_layer, outputs=[output1_xy,output2_angles]) \n",
    "\n",
    "        dt = time.strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "\n",
    "        # summarize layers\n",
    "        from contextlib import redirect_stdout\n",
    "        file = dir14 + '/' + test_runNum + '-' + dt +'.txt'\n",
    "        with open(file, 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                model.summary()\n",
    "        print(model.summary())\n",
    "\n",
    "\n",
    "        # plot graph\n",
    "        plot_model(model, to_file=(dir11 + test_runNum + '-convolutional_neural_network_' + dt + '.png'))\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=0.00001),loss={'output1_xy':'mae','output2_angles':cyclic_mean_abs_error},\n",
    "                      metrics=['mse','acc'])\n",
    "\n",
    "\n",
    "        return model\n",
    "    \n",
    "    elif angles == 'no':\n",
    "        input_layer = Input(shape=(108,192,3))\n",
    "    \n",
    "        ## Downsampling here (Flexible to alter)\n",
    "        X = Conv2D(64, kernel_size=(7,7), activation='relu', strides = (1,1), padding='same')(input_layer)\n",
    "        for l in range(0, num_layers):\n",
    "            X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,1), padding='same')(X)\n",
    "            X = Dropout(0.25)(X)\n",
    "            X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (1,2), padding='same')(X)\n",
    "            X = Dropout(0.25)(X)\n",
    "            X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,2), padding='same')(X)\n",
    "            X = Dropout(0.25)(X) \n",
    "\n",
    "        X = Flatten()(X)\n",
    "        #X = Dense(128, activation=\"linear\")(X) #X = Dense(128)(X) # linear is default\n",
    "        X = Dense(dense, activation=\"linear\")(X)\n",
    "        # OR\n",
    "        #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001), \n",
    "        #          activity_regularizer=regularizers.l2(0.001),bias_regularizer=regularizers.l2(0.001))(X)\n",
    "        # OR\n",
    "        #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), \n",
    "        #          activity_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "        #          ,bias_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(X)\n",
    "        #X = Dropout(0.50)(X)\n",
    "\n",
    "        output = Dense(2, activation=\"linear\")(X) # linear is default\n",
    "        model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "        dt = time.strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "\n",
    "        # summarize layers\n",
    "        from contextlib import redirect_stdout\n",
    "        #file = dir14 + '/' + dt +'.txt'\n",
    "        file = dir14 + '/' + test_runNum + '-' + dt +'.txt'\n",
    "        with open(file, 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                model.summary()\n",
    "        print(model.summary())\n",
    "\n",
    "\n",
    "        # plot graph\n",
    "        plot_model(model, to_file=(dir11 + test_runNum + '-convolutional_neural_network_' + dt + '.png'))\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=0.00001),loss='mae', metrics=['mse','acc'])\n",
    "\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMP for replot of failed model #\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def mish(x):\n",
    "    return x * K.tanh(K.softplus(x))\n",
    "\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras.layers import Activation\n",
    "get_custom_objects().update({'mish': Activation(mish)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mainly have modified the part without including angles for my initial report\n",
    "# Please modify according to need if necessary\n",
    "# Did not include this part in my report at last because cannot think of a valid reason in explaining the result\n",
    "\n",
    "def create_cnn_functional_model_WeightsPerturb(angles,num_layers,randomise,randomiseMethod):\n",
    "    if angles == 'yes':\n",
    "        input_layer = Input(shape=(108,192,3))\n",
    "\n",
    "        ## Downsampling here (Flexible to alter)\n",
    "        X = Conv2D(64, kernel_size=(7,7), activation='relu', strides = (1,1), padding='same')(input_layer)\n",
    "        for l in range(0, num_layers):\n",
    "            X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,1), padding='same')(X)\n",
    "            X = Dropout(0.25)(X)\n",
    "            X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (1,2), padding='same')(X)\n",
    "            X = Dropout(0.25)(X)\n",
    "            X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,2), padding='same')(X)\n",
    "            X = Dropout(0.25)(X) \n",
    "\n",
    "        X = Flatten()(X)\n",
    "        X = Dense(128, activation=\"linear\", kernel_regularizer=regularizers.l2(0.01), \n",
    "                  activity_regularizer=regularizers.l2(0.01),bias_regularizer=regularizers.l2(0.01))(X)\n",
    "        #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.01, l2=0.01), \n",
    "        #          activity_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005)\n",
    "        #          ,bias_regularizer=regularizers.l1_l2(l1=0.005, l2=0.005))(X)\n",
    "        X = Dropout(0.50)(X)\n",
    "\n",
    "        #output = Dense(3, activation=\"linear\")(X) # linear is default\n",
    "        #model = Model(inputs=input_layer, outputs=output)\n",
    "        output1_xy = Dense(units=2, activation=\"linear\",name='output1_xy')(X) # linear is default\n",
    "        output2_angles = Dense(units=1, activation=\"linear\",name='output2_angles')(X) # linear is default\n",
    "        model = Model(inputs=input_layer, outputs=[output1_xy,output2_angles]) \n",
    "\n",
    "        dt = time.strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "\n",
    "        # summarize layers\n",
    "        from contextlib import redirect_stdout\n",
    "        file = dir14 + '/' + test_runNum + '-' + dt +'.txt'\n",
    "        with open(file, 'w') as f:\n",
    "            with redirect_stdout(f):\n",
    "                model.summary()\n",
    "        print(model.summary())\n",
    "\n",
    "\n",
    "        # plot graph\n",
    "        plot_model(model, to_file=(dir11 + test_runNum + '-convolutional_neural_network_' + dt + '.png'))\n",
    "\n",
    "        model.compile(optimizer=Adam(lr=0.00001),loss={'output1_xy':'mae','output2_angles':cyclic_mean_abs_error},\n",
    "                      metrics=['mse','acc'])\n",
    "\n",
    "\n",
    "        return model\n",
    "    \n",
    "    elif angles == 'no':\n",
    "        if randomise == 'no':\n",
    "            input_layer = Input(shape=(108,192,3))\n",
    "    \n",
    "            ## Downsampling here (Flexible to alter)\n",
    "            X = Conv2D(64, kernel_size=(7,7), activation='relu', strides = (1,1), padding='same')(input_layer)\n",
    "            for l in range(0, num_layers):\n",
    "                X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,1), padding='same')(X)\n",
    "                X = Dropout(0.25)(X)\n",
    "                X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (1,2), padding='same')(X)\n",
    "                X = Dropout(0.25)(X)\n",
    "                X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,2), padding='same')(X)\n",
    "                X = Dropout(0.25)(X) \n",
    "\n",
    "            X = Flatten()(X)\n",
    "            #X = Dense(128, activation=\"linear\")(X) #X = Dense(128)(X) # linear is default\n",
    "            X = Dense(dense, activation=\"linear\")(X)\n",
    "            # OR\n",
    "            #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001), \n",
    "            #          activity_regularizer=regularizers.l2(0.001),bias_regularizer=regularizers.l2(0.001))(X)\n",
    "            # OR\n",
    "            #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), \n",
    "            #          activity_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "            #          ,bias_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(X)\n",
    "            #X = Dropout(0.50)(X)\n",
    "\n",
    "            output = Dense(2, activation=\"linear\")(X) # linear is default\n",
    "            model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "            dt = time.strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "\n",
    "            # summarize layers\n",
    "            from contextlib import redirect_stdout\n",
    "            #file = dir14 + '/' + dt +'.txt'\n",
    "            file = dir14 + '/' + test_runNum + '-' + dt +'.txt'\n",
    "            with open(file, 'w') as f:\n",
    "                with redirect_stdout(f):\n",
    "                    model.summary()\n",
    "            print(model.summary())\n",
    "\n",
    "\n",
    "            # plot graph\n",
    "            plot_model(model, to_file=(dir11 + test_runNum + '-convolutional_neural_network_' + dt + '.png'))\n",
    "\n",
    "            #model.compile(optimizer=Adam(lr=0.00001),loss='mae', metrics=['mse','acc'])\n",
    "            model.compile(optimizer=Adam(lr=lr_rate),loss='mae', metrics=['mse','acc'])\n",
    "        \n",
    "        elif randomise == 'yes': ## Added to try the randomization ##\n",
    "            if randomiseMethod == '1': # just permutation, not helpful to get what we want\n",
    "                input_layer = Input(shape=(108,192,3))\n",
    "    \n",
    "                ## Downsampling here (Flexible to alter)\n",
    "                X = Conv2D(64, kernel_size=(7,7), activation='relu', strides = (1,1), padding='same')(input_layer)\n",
    "                for l in range(0, num_layers):\n",
    "                    X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,1), padding='same')(X)\n",
    "                    X = Dropout(0.25)(X)\n",
    "                    X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (1,2), padding='same')(X)\n",
    "                    X = Dropout(0.25)(X)\n",
    "                    X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,2), padding='same')(X)\n",
    "                    X = Dropout(0.25)(X) \n",
    "\n",
    "                X = Flatten()(X)\n",
    "                #X = Dense(128, activation=\"linear\")(X) #X = Dense(128)(X) # linear is default\n",
    "                X = Dense(dense, activation=\"linear\")(X)\n",
    "                # OR\n",
    "                #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001), \n",
    "                #          activity_regularizer=regularizers.l2(0.001),bias_regularizer=regularizers.l2(0.001))(X)\n",
    "                # OR\n",
    "                #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), \n",
    "                #          activity_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "                #          ,bias_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(X)\n",
    "                #X = Dropout(0.50)(X)\n",
    "\n",
    "                output = Dense(2, activation=\"linear\")(X) # linear is default\n",
    "                model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "                dt = time.strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "\n",
    "                # summarize layers\n",
    "                from contextlib import redirect_stdout\n",
    "                #file = dir14 + '/' + dt +'.txt'\n",
    "                file = dir14 + '/' + test_runNum + '-' + dt +'.txt'\n",
    "                with open(file, 'w') as f:\n",
    "                    with redirect_stdout(f):\n",
    "                        model.summary()\n",
    "                print(model.summary())\n",
    "\n",
    "\n",
    "                # plot graph\n",
    "                #plot_model(model, to_file=(dir11 + 'convolutional_neural_network_' + dt + '.png'))\n",
    "                plot_model(model, to_file=(dir11 + test_runNum + '-convolutional_neural_network_' + dt + '.png'))\n",
    "\n",
    "                model.compile(optimizer=Adam(lr=0.00001),loss='mae', metrics=['mse','acc'])\n",
    "        \n",
    "        \n",
    "                # 1. Personalized randomisation: https://gist.github.com/jkleint/eb6dc49c861a1c21b612b568dd188668\n",
    "                # https://github.com/keras-team/keras/issues/341\n",
    "\n",
    "                initial_weights = model.get_weights()\n",
    "                print('Initial weights:\\n', initial_weights)\n",
    "\n",
    "                def shuffle_weights(model, weights=None):\n",
    "\n",
    "                    #\"\"\"Randomly permute the weights in `model`, or the given `weights`.\n",
    "                    #This is a fast approximation of re-initializing the weights of a model.\n",
    "                    #Assumes weights are distributed independently of the dimensions of the weight tensors\n",
    "                    #  (i.e., the weights have the same distribution along each dimension).\n",
    "                    #:param Model model: Modify the weights of the given model.\n",
    "                    #:param list(ndarray) weights: The model's weights will be replaced by a random permutation of these weights.\n",
    "                    #  If `None`, permute the model's current weights.\n",
    "                    #\"\"\"\n",
    "                    if weights is None:\n",
    "                        weights = model.get_weights()\n",
    "                    weights = [np.random.permutation(w.flat).reshape(w.shape) for w in weights]\n",
    "                    # Faster, but less random: only permutes along the first dimension\n",
    "                    # weights = [np.random.permutation(w) for w in weights]\n",
    "                    model.set_weights(weights)\n",
    "\n",
    "                for rnd in range(25):\n",
    "                    shuffle_weights(model, initial_weights)\n",
    "                    print('\\nRound {} starting weights:\\n'.format(rnd), model.get_weights())\n",
    "            \n",
    "            elif randomiseMethod == '2': # perturbing directly over the inputs with kernel and bias initializers\n",
    "                input_layer = Input(shape=(108,192,3))\n",
    "    \n",
    "                ## Downsampling here (Flexible to alter)\n",
    "                X = Conv2D(64, kernel_size=(7,7), activation='relu', strides = (1,1), padding='same')(input_layer)\n",
    "                for l in range(0, num_layers):\n",
    "                    X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,1), padding='same',\n",
    "                               kernel_initializer='he_normal', bias_initializer='ones')(X)\n",
    "                    X = Dropout(0.25)(X)\n",
    "                    X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (1,2), padding='same',\n",
    "                              kernel_initializer='he_normal', bias_initializer='ones')(X)\n",
    "                    X = Dropout(0.25)(X)\n",
    "                    X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,2), padding='same',\n",
    "                              kernel_initializer='he_normal', bias_initializer='ones')(X)\n",
    "                    X = Dropout(0.25)(X) \n",
    "\n",
    "                X = Flatten()(X)\n",
    "                #X = Dense(128, activation=\"linear\")(X) #X = Dense(128)(X) # linear is default\n",
    "                X = Dense(dense, activation=\"linear\")(X)\n",
    "                # OR\n",
    "                #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001), \n",
    "                #          activity_regularizer=regularizers.l2(0.001),bias_regularizer=regularizers.l2(0.001))(X)\n",
    "                # OR\n",
    "                #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), \n",
    "                #          activity_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "                #          ,bias_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(X)\n",
    "                #X = Dropout(0.50)(X)\n",
    "\n",
    "                output = Dense(2, activation=\"linear\")(X) # linear is default\n",
    "                model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "                dt = time.strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "\n",
    "                # summarize layers\n",
    "                from contextlib import redirect_stdout\n",
    "                #file = dir14 + '/' + dt +'.txt'\n",
    "                file = dir14 + '/' + test_runNum + '-' + dt +'.txt'\n",
    "                with open(file, 'w') as f:\n",
    "                    with redirect_stdout(f):\n",
    "                        model.summary()\n",
    "                print(model.summary())\n",
    "\n",
    "\n",
    "                # plot graph\n",
    "                plot_model(model, to_file=(dir11 + test_runNum + '-convolutional_neural_network_' + dt + '.png'))\n",
    "\n",
    "                model.compile(optimizer=Adam(lr=0.00001),loss='mae', metrics=['mse','acc'])\n",
    "                # 2. Use initializer:\n",
    "                 # https://towardsdatascience.com/weight-initialization-in-neural-networks-a-journey-from-the-basics-to-kaiming-954fb9b47c79\n",
    "                 # https://machinelearningmastery.com/why-initialize-a-neural-network-with-random-weights/\n",
    "                 # https://keras.io/initializers/\n",
    "                 # https://stackoverflow.com/questions/56630174/how-to-re-initialize-layer-weights-of-an-existing-model-in-keras\n",
    "                 # https://www.tensorflow.org/api_docs/python/tf/keras/initializers/Initializer\n",
    "                 # https://blog.goodaudience.com/visualizing-various-filter-initializers-in-keras-ca14c996db22\n",
    "                 # https://keras.rstudio.com/articles/guide_keras.html\n",
    "        \n",
    "            elif randomiseMethod == '3': # set initial weights to zeros and set bias to the inputs\n",
    "                input_layer = Input(shape=(108,192,3))\n",
    "    \n",
    "                ## Downsampling here (Flexible to alter)\n",
    "                X = Conv2D(64, kernel_size=(7,7), activation='relu', strides = (1,1), padding='same')(input_layer)\n",
    "                for l in range(0, num_layers):\n",
    "                    X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,1), padding='same',\n",
    "                               bias_initializer='ones')(X)\n",
    "                    X = Dropout(0.25)(X)\n",
    "                    X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (1,2), padding='same',\n",
    "                               bias_initializer='ones')(X)\n",
    "                    X = Dropout(0.25)(X)\n",
    "                    X = Conv2D(64*(l+1), kernel_size=(7,7), activation='relu', strides = (2,2), padding='same',\n",
    "                               bias_initializer='ones')(X)\n",
    "                    X = Dropout(0.25)(X) \n",
    "\n",
    "                X = Flatten()(X)\n",
    "                #X = Dense(128, activation=\"linear\")(X) #X = Dense(128)(X) # linear is default\n",
    "                X = Dense(dense, activation=\"linear\")(X)\n",
    "                # OR\n",
    "                #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l2(0.001), \n",
    "                #          activity_regularizer=regularizers.l2(0.001),bias_regularizer=regularizers.l2(0.001))(X)\n",
    "                # OR\n",
    "                #X = Dense(128, activation=\"relu\", kernel_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001), \n",
    "                #          activity_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001)\n",
    "                #          ,bias_regularizer=regularizers.l1_l2(l1=0.001, l2=0.001))(X)\n",
    "                #X = Dropout(0.50)(X)\n",
    "\n",
    "                output = Dense(2, activation=\"linear\")(X) # linear is default\n",
    "                model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "                dt = time.strftime(\"%Y-%m-%d_%H.%M.%S\")\n",
    "\n",
    "                # summarize layers\n",
    "                from contextlib import redirect_stdout\n",
    "                #file = dir14 + '/' + dt +'.txt'\n",
    "                file = dir14 + '/' + test_runNum + '-' + dt +'.txt'\n",
    "                with open(file, 'w') as f:\n",
    "                    with redirect_stdout(f):\n",
    "                        model.summary()\n",
    "                print(model.summary())\n",
    "\n",
    "\n",
    "                # plot graph\n",
    "                plot_model(model, to_file=(dir11 + test_runNum + '-convolutional_neural_network_' + dt + '.png'))\n",
    "\n",
    "                model.compile(optimizer=Adam(lr=0.00001),loss='mae', metrics=['mse','acc'])\n",
    "                \n",
    "                \n",
    "                #model.layers[i].set_weights(listOfNumpyArrays)    \n",
    "                #model.get_layer(layerName).set_weights(...)\n",
    "                #model.set_weights(listOfNumpyArrays)\n",
    "                \n",
    "                #https://keras.io/models/about-keras-models/\n",
    "                \n",
    "                \n",
    "                initial_weights = model.get_weights()\n",
    "                print('Initial weights:\\n', initial_weights)\n",
    "\n",
    "                def set_weightsZeros(model, weights):#=None):\n",
    "                    \n",
    "                    #if weights is None:\n",
    "                    #    weights = model.get_weights()\n",
    "                    weights = [np.zeros(w.shape) for w in weights]\n",
    "                    model.set_weights(weights)\n",
    "\n",
    "                set_weightsZeros(model, initial_weights)\n",
    "                print('New weights:\\n', model.get_weights())\n",
    "                \n",
    "                \n",
    "                \n",
    "            # 4. Read https://arxiv.org/pdf/1602.05931.pdf\n",
    "\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
